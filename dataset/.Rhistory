total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
#set a seed for random number generation  to make the results reproducible
set.seed(8953)
kmeans.result <- kmeans(dataset, 3)
# print the clusterng result
kmeans.result
# visualize clustering (2 clusters)
#install.packages("factoextra")
library(factoextra)
fviz_cluster(kmeans.result, data = dataset)
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(dataset))
fviz_silhouette(avg_sil)
kmeans.result$tot.withinss
cluster_assignments <- c(kmeans.result$cluster)
ground_truth_labels <- c(dataWithclass$class)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
#set a seed for random number generation  to make the results reproducible
set.seed(8953)
kmeans.result <- kmeans(dataset, 4)
# print the clusterng result
kmeans.result
# visualize clustering (2 clusters)
#install.packages("factoextra")
library(factoextra)
fviz_cluster(kmeans.result, data = dataset)
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(dataset))
fviz_silhouette(avg_sil)
kmeans.result$tot.withinss
cluster_assignments <- c(kmeans.result$cluster)
ground_truth_labels <- c(dataWithclass$class)
data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)
# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
n <- nrow(data)
precision_sum <- 0
recall_sum <- 0
for (i in 1:n) {
cluster <- data$cluster[i]
label <- data$label[i]
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
}
# Calculate average precision and recall
precision <- precision_sum / n
recall <- recall_sum / n
return(list(precision = precision, recall = recall))
}
# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)
# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall
# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 4)+
labs(subtitle = "Elbow method")
library(fpc)
kmeansruns.result <- kmeansruns(dataset)
kmeansruns.result
dataset<- read.csv("bodyPerformance.csv")
View(dataset)
str(dataset)
print(dataset)
#Number of rows
nrow(dataset)
#Number of column
ncol(dataset)
#encoding Class:
dataset$class = factor(dataset$class,levels =
c("A","B", "C","D"), labels = c(1, 2, 3,4))
#encoding Gender:
dataset$gender = factor(dataset$gender,levels =
c("F","M"), labels = c(0,1))
boxplot(dataset$class,
ylab= "The person’s class boxplot",
main= "Boxplot of class")
plot(dataset$gender, dataset$class, main = " the performance between meal amd female",
xlab = "gender", ylab = "class",
xlim = c(0,1), ylim = c(0,4))
plot(dataset$gender, dataset$class, main = " the performance between meal amd female",
xlab = "gender", ylab = "class",
xlim = c(0,1), ylim = c(0,4))
plot(dataset$height_cm, dataset$weight_kg, main = "Body Measurement",
xlab = "height", ylab = "weight",
xlim = c(100,200), ylim = c(20,150))
hist(dataset$body.fat_.)
plot(dataset$age, dataset$diastolic, main = "",
xlab = "age", ylab = "diastolic",
xlim = c(20,64), ylim = c(0,200))
plot(dataset$age, dataset$gripForce, main = "",
xlab = "age", ylab = "gripForce",
xlim = c(20,64), ylim = c(20,71 ))
dataset
plot(dataset$broad.jump_cm, dataset$weight_kg,
xlab = "broad.jump_cm", ylab = "weight_kg",
xlim = c(0,303), ylim = c(26.3,138 ))
summary(dataset$age)
summary(dataset$height_cm)
summary(dataset$weight_kg)
```{r}
summary(dataset$body.fat_.)
summary(dataset$diastolic)
summary(dataset$systolic)
summary(dataset$gripForce)
summary(dataset$sit.and.bend.forward_cm)
summary(dataset$sit.ups.counts)
summary(dataset$broad.jump_cm)
sum(duplicated(dataset))
#Remove duplicated rows
dataset <- dataset[!duplicated (dataset), ]
#To make sure that the deletion was successful
sum(duplicated(dataset))
#to find the total null values in the dataset
sum(is.na(dataset))
#install outliers package:
library(outliers)
# age boxplot :
boxplot(dataset$age ,
ylab= "The person’s age in years boxplot",
main= "Boxplot of age")
#Hight boxplot :
boxplot(dataset$height_cm ,
ylab= "The person’s height in cm",
main= "Boxplot of height_cm")
#Weight boxplot;
boxplot(dataset$weight_kg ,
ylab= "The person’s weight in Kg",
main= "Boxplot of weight")
#body fat boxplot :
boxplot(dataset$body.fat_.,
ylab= "the person's body fat" ,
main= "Boxplot of body fat_%")
#diastolic box plot :
boxplot(dataset$diastolic,
ylab= "the person's diastolic ",
main= "Boxplot of diastolic")
#systolic box plot:
boxplot(dataset$systolic,
ylab= "The person's systolic " ,
main= "Boxplot of systolic")
#gripForce box plot:
boxplot(dataset$gripForc,
ylab= "the person's gripForce " ,
main= "Boxplot of gripForc")
#sit and bend forward_cm box plot:
boxplot(dataset$sit.and.bend.forward_cm,
ylab= "sit and bend forward_cm" ,
main= "Boxplot of sit and bend forward_cm")
#sit-ups counts_cm box plot:
boxplot(dataset$sit.ups.counts,
ylab= "sit-ups" ,
main= "Boxplot of sit-ups")
#broad jump_cm box plot:
boxplot(dataset$broad.jump_cm,
ylab= "broad jump_cm " ,
main= "Boxplot of broad jump_cm ")
#Detect outlir for 'age':
outAge = outlier(dataset$age, logical =TRUE)
#number of outliers:
sum(outAge)
Find_outlier = which(outAge ==TRUE, arr.ind = TRUE)
outAge
Find_outlier
#Delete age outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'height_cm':
outH = outlier(dataset$height_cm, logical =TRUE)
#number of outliers:
sum(outH)
Find_outlier = which(outH ==TRUE, arr.ind = TRUE)
outH
Find_outlier
#Delete height_cm outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'weight_kg':
outW= outlier(dataset$weight_kg, logical =TRUE)
#number of outliers:
sum(outW)
Find_outlier = which(outW ==TRUE, arr.ind = TRUE)
outW
Find_outlier
#Delete weight_kg outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'body.fat\_.':
outefat = outlier(dataset$body.fat_., logical =TRUE)
#number of outliers:
sum(outefat)
Find_outlier = which(outefat ==TRUE, arr.ind = TRUE)
outefat
Find_outlier
#Delete body.fat outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'systolic':
outesys = outlier(dataset$systolic, logical =TRUE)
#number of outliers:
sum(outesys)
Find_outlier = which(outesys ==TRUE, arr.ind = TRUE)
outesys
Find_outlier
#Delete systolic outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'gripForce':
outegrip = outlier(dataset$gripForce, logical =TRUE)
#number of outliers:
sum(outegrip)
Find_outlier = which(outegrip ==TRUE, arr.ind = TRUE)
outegrip
Find_outlier
#Delete gripForce  outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'sit.and.bend.forward_cm':
outesit = outlier(dataset$sit.and.bend.forward_cm, logical =TRUE)
#number of outliers:
sum(outesit)
Find_outlier = which(outesit ==TRUE, arr.ind = TRUE)
outesit
Find_outlier
#Delete sit.and.bend.forward_cm outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'sit.up.count':
outesitup = outlier(dataset$sit.ups.counts, logical =TRUE)
#number of outliers:
sum(outesitup)
Find_outlier = which(outesitup ==TRUE, arr.ind = TRUE)
outesitup
Find_outlier
#Delete age outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'broad.jump_cm':
Outjump = outlier(dataset$broad.jump_cm, logical =TRUE)
sum(Outjump)
Find_outlier = which(Outjump ==TRUE, arr.ind = TRUE)
Outjump
Find_outlier
dataset= dataset[-Find_outlier,]
#Number of rows
nrow(dataset)
#Number of column
ncol(dataset)
#To use it later in clustering task:
AgeBeforeDis <- dataset$age
# Define bins for discretization
dataset$age=cut(dataset$age, breaks = seq(21,64, by=14), right=FALSE)
dataset [,3:4:5:6:7:8:9:11]=scale(dataset [,3:4:5:6:7:8:9:11])
library(party)
library(partykit)
library(RWeka)
library(caret)
library(rpart)
library(rpart.plot)
#in case we need the dataset with class label
dataWithclass <-dataset
#delete class label
dataset <- dataset [,-which(names(dataset)== "class")]
#varify removing class
str(dataset)
dataset$age <- AgeBeforeDis
#verify updating
str(dataset)
dataset$gender <- as.numeric(as.character(dataset$gender))
# Verify the conversion and all other attribute class type
sapply(dataset, class)
#install necessary packages:
library(factoextra)
library(fpc)
library(cluster)
library(NbClust)
library(fpc)
kmeansruns.result <- kmeansruns(dataset)
kmeansruns.result
fviz_cluster(kmeansruns.result, data = dataset)
library(NbClust)
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
dataset<- read.csv("bodyPerformance.csv")
View(dataset)
str(dataset)
#Number of rows
nrow(dataset)
#Number of column
ncol(dataset)
#encoding Class:
dataset$class = factor(dataset$class,levels =
c("A","B", "C","D"), labels = c(1, 2, 3,4))
#encoding Gender:
dataset$gender = factor(dataset$gender,levels =
c("F","M"), labels = c(0,1))
sum(duplicated(dataset))
#Remove duplicated rows
dataset <- dataset[!duplicated (dataset), ]
#To make sure that the deletion was successful
sum(duplicated(dataset))
#to find the total null values in the dataset
sum(is.na(dataset))
#install outliers package:
library(outliers)
#Detect outlir for 'age':
outAge = outlier(dataset$age, logical =TRUE)
#number of outliers:
sum(outAge)
Find_outlier = which(outAge ==TRUE, arr.ind = TRUE)
outAge
Find_outlier
#Delete age outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'height_cm':
outH = outlier(dataset$height_cm, logical =TRUE)
#number of outliers:
sum(outH)
Find_outlier = which(outH ==TRUE, arr.ind = TRUE)
outH
Find_outlier
#Delete height_cm outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'weight_kg':
outW= outlier(dataset$weight_kg, logical =TRUE)
#number of outliers:
sum(outW)
Find_outlier = which(outW ==TRUE, arr.ind = TRUE)
outW
Find_outlier
#Delete weight_kg outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'body.fat\_.':
outefat = outlier(dataset$body.fat_., logical =TRUE)
#number of outliers:
sum(outefat)
Find_outlier = which(outefat ==TRUE, arr.ind = TRUE)
outefat
Find_outlier
#Delete body.fat outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'systolic':
outesys = outlier(dataset$systolic, logical =TRUE)
#number of outliers:
sum(outesys)
Find_outlier = which(outesys ==TRUE, arr.ind = TRUE)
outesys
Find_outlier
#Delete systolic outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'gripForce':
outegrip = outlier(dataset$gripForce, logical =TRUE)
#number of outliers:
sum(outegrip)
Find_outlier = which(outegrip ==TRUE, arr.ind = TRUE)
outegrip
Find_outlier
#Delete gripForce  outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'sit.and.bend.forward_cm':
outesit = outlier(dataset$sit.and.bend.forward_cm, logical =TRUE)
#number of outliers:
sum(outesit)
Find_outlier = which(outesit ==TRUE, arr.ind = TRUE)
outesit
Find_outlier
#Delete sit.and.bend.forward_cm outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'sit.up.count':
outesitup = outlier(dataset$sit.ups.counts, logical =TRUE)
#number of outliers:
sum(outesitup)
Find_outlier = which(outesitup ==TRUE, arr.ind = TRUE)
outesitup
Find_outlier
#Delete age outliers:
dataset= dataset[-Find_outlier,]
#Detect outlir for 'broad.jump_cm':
Outjump = outlier(dataset$broad.jump_cm, logical =TRUE)
sum(Outjump)
Find_outlier = which(Outjump ==TRUE, arr.ind = TRUE)
Outjump
Find_outlier
dataset= dataset[-Find_outlier,]
#Number of rows
nrow(dataset)
#Number of column
ncol(dataset)
#To use it later in clustering task:
AgeBeforeDis <- dataset$age
# Define bins for discretization
dataset$age=cut(dataset$age, breaks = seq(21,64, by=14), right=FALSE)
dataset [,3:4:5:6:7:8:9:11]=scale(dataset [,3:4:5:6:7:8:9:11])
library(party)
library(partykit)
library(RWeka)
library(caret)
library(rpart)
library(rpart.plot)
set.seed(1234)
ind=sample(2, nrow(dataset), replace=TRUE, prob=c(0.70 , 0.30))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)
# Check class distribution in training set
table(train_data$class)
prop.table(table(train_data$class))
# Check class distribution in testing set
table(test_data$class)
prop.table(table(test_data$class))
features <-dataset[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")]
target <- as.factor(dataset$class)
dataset$class = as.factor(dataset$class)
# Example of hyperparameter tuning
model <- train(
x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
y = train_data$class,
method = "rpart",parms = list(split = "information"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3)
)
# Load the necessary libraries
library(rpart)
library(rpart.plot)
# Assuming 'model' is your trained model
rpart_model <- model$finalModel
# Print the decision tree
rpart.plot(rpart_model,main="ID3 70/30", box.palette = "auto", nn = TRUE)
#in case we need the dataset with class label
dataWithclass <-dataset
#delete class label
dataset <- dataset [,-which(names(dataset)== "class")]
#varify removing class
str(dataset)
dataset$age <- AgeBeforeDis
#verify updating
str(dataset)
dataset$gender <- as.numeric(as.character(dataset$gender))
# Verify the conversion and all other attribute class type
sapply(dataset, class)
#install necessary packages:
library(factoextra)
library(fpc)
library(cluster)
library(NbClust)
library(fpc)
kmeansruns.result <- kmeansruns(dataset)
kmeansruns.result
fviz_cluster(kmeansruns.result, data = dataset)
library(NbClust)
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 3)+
labs(subtitle = "Elbow method")
library(factoextra)
fviz_nbclust(dataset, kmeans, method = "wss") +
geom_vline(xintercept = 4, linetype = 3)+
labs(subtitle = "Elbow method")
