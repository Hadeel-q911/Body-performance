---
title: "Body performance"
output: html_notebook
editor_options: 
  markdown: 
    wrap: 72
---

## 1. Problem:

With the increasing prevalence of smartphones, technology has had a
profound impact on our daily lives, including how we interact with our
bodies.By analyzing the body performance dataset, We aim to solve the
problem of understanding the factors that contribute to optimal body
performance and developing practical solutions.This research is crucial
because it can improve athletic performance, prevent injuries, and
enhance overall well-being. By analyzing the dataset, we hope to uncover
patterns and correlations that will help us optimize training programs.

### Goal :

The primary objective of this project is to emphasize the significance
of body performance in enhancing physical health and promoting exercise
awareness among individuals. This will be accomplished by analyzing and
extracting valuable insights from body performance datasets, monitoring
the progression of human age, and subsequently improving the overall
awareness of its importance.

------------------------------------------------------------------------

## 2. Data Mining task:

### 2.1 Classification goal :

Using the attribute "class" as our class label, we employ a
classification approach to categorize individuals into different levels
of fitness. This classification is based on a range of data attributes,
including body measurements such as weight, body fat percentage, health
indicators, and activity levels. Our objective extends beyond
classification, as we also strive to predict performance outcomes by
leveraging the collected data.

### 2.2 Clustering goal :

Our primary goal in utilizing clustering on our dataset is to identify
inherent patterns or groupings within the data. By applying clustering
algorithms, we aim to partition the dataset into distinct clusters based
on similarities or shared characteristics among the data points. This
enables us to gain insights into the underlying structure of the data,
discover relationships between data points, and potentially uncover
valuable knowledge or trends that may be hidden within the dataset.

------------------------------------------------------------------------

## 3. Data:

### 3.1: Data Source :

Body performance dataset it from Kaggle website , The
link(<https://www.kaggle.com/datasets/kukuroo3/body-performance-data>)
show the source data. ^[[1]](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)^

### 3.2: General Information about Body performance dataset :

Our dataset is called "Body performance" ,the dataset provide the grade
of performance and some data such as gender and age along with body
measurements and other performance tests ,it has 13394 row and each of
them have 12 attributes.

+----------+-------------------------------+----------+----------+
| name     | description                   | data     | p        |
|          |                               | type     | ossible  |
|          |                               |          | value    |
+==========+===============================+==========+==========+
| Age      | The person's age in years     | nu       | 21-64    |
|          |                               | merical  |          |
+----------+-------------------------------+----------+----------+
| Gender   | The person's gender           | binary   | F,M      |
+----------+-------------------------------+----------+----------+
| He       | The person's Height in cm     | nu       | 125-194  |
| ight_cm  |                               | merical  |          |
+----------+-------------------------------+----------+----------+
| we       | The person's weight in Kg     | nu       | 2        |
| ight_kg  |                               | merical  | 6.3-138  |
+----------+-------------------------------+----------+----------+
| body     | the amount of essential fat . | nu       | 3        |
| fat\_%   |                               | merical  | %-78.4%  |
+----------+-------------------------------+----------+----------+
| di       | measures pressure the blood   | nu       | 0-156    |
| astolic  | vessels when the heart is at  | merical  |          |
|          | rest                          |          |          |
+----------+-------------------------------+----------+----------+
| s        | measures pressure in the      | nu       | 0-201    |
| ystolic  | arteries when the heart beats | merical  |          |
|          | in minutes                    |          |          |
+----------+-------------------------------+----------+----------+
| gr       | fingers f lexibility tests    | nu       | 0-70.5   |
| ipForce  |                               | merical  |          |
+----------+-------------------------------+----------+----------+
| sit and  | measures f lexibility in      | nu       | -25-213  |
| bend for | sitting and bending forward   | merical  |          |
| ward_cm  | in ce ntimeters.              |          |          |
+----------+-------------------------------+----------+----------+
| sit-ups  | measures the strength and     | nu       | 0-80     |
| co       | endurance of the abdominals   | merical  |          |
| unts_cm  | and hip-flexor muscles in c   |          |          |
|          | entimeter.                    |          |          |
+----------+-------------------------------+----------+----------+
| broad    | It is a method of measuring   | nu       | 0-303    |
| jump_cm  | how far a person can jump     | merical  |          |
|          | from a standing position to a |          |          |
|          | landing position.             |          |          |
+----------+-------------------------------+----------+----------+
| class    | body p erformance score       | nu       | A,B,C,D  |
|          |                               | merical  |          |
+----------+-------------------------------+----------+----------+

: Table 1: Data dictionary attributes

------------------------------------------------------------------------

### 3.3: Importing the dataset:

```{r}
dataset<- read.csv("bodyPerformance.csv")
View(dataset)
str(dataset)
```

------------------------------------------------------------------------

## 4. Data Preprocessing:

### 4.1 performance dataset before preprocessing:

```{r}
print(dataset)
```


```{r}
#Number of rows
nrow(dataset)

#Number of column
ncol(dataset)
```

------------------------------------------------------------------------

### ^[[2]](https://www.kaggle.com/code/codeguyas101/body-performance-data-eda),[[6]](https://www.kaggle.com/code/shivanirana63/guide-to-complete-statistical-analysis)^4.2 Understanding the dataset using graph representations:

### Encoding:

In order to represent the nominal attributes (gender) and (class) in
graphs, we had to encode them as they cannot be directly displayed in
their original form.

```{r}
 #encoding Class: 
dataset$class = factor(dataset$class,levels =
                        c("A","B", "C","D"), labels = c(1, 2, 3,4))
```

```{r}
 #encoding Gender:
dataset$gender = factor(dataset$gender,levels =
                         c("F","M"), labels = c(0,1))
```

------------------------------------------------------------------------

### Check if the dataset is balanced or imbalanced (Class boxplot) :

After encoding the attribute (class) We employ a Boxplot graph on our
class label (class) to ascertain whether our dataset is balanced or not.

```{r}
boxplot(dataset$class, 
        ylab= "The person’s class boxplot", 
        main= "Boxplot of class")
```

Since the median is positioned in the middle of the box plot, it
indicates that our dataset is balanced, and there is no need to perform
any sampling.

------------------------------------------------------------------------

#### 1- Scatter plot for Gender and class :

first we endcode the gender F to be 0 and M to 1, then we use the plot
to determine the relationship between gender and class attributes , we
notice that the female have higher performance then male.

```{r}
plot(dataset$gender, dataset$class, main = " the performance between meal amd female", 
     xlab = "gender", ylab = "class",
     xlim = c(0,1), ylim = c(0,4))
```


------------------------------------------------------------------------

#### 2- Scatter plot of height and weight:

Observation:

This scatter plot helps us determine whether height and weight are
correlated to each other or not. The plot shows a strong positive
correlation between the two attributes, indicating a proportional
relationship.

```{r}
plot(dataset$height_cm, dataset$weight_kg, main = "Body Measurement", 
     xlab = "height", ylab = "weight",
     xlim = c(100,200), ylim = c(20,150))
```

------------------------------------------------------------------------

#### 3- Histogram of body fat :

Observation:

the histogram represents the frequency distribution of body fat values.
We observe that the majority of values lie within the range of 10-30.
However, the histogram also reveals the presence of outliers in the
dataset.

```{r}
hist(dataset$body.fat_.)
```

------------------------------------------------------------------------

#### 4- Scatter plot for age and diastoic :

Observation :

This scatter plot helps us determine the correlation between Age and
diastolic. The plot shows no correlation between the two attributes,
indicating no proportional relationship

```{r}
plot(dataset$age, dataset$diastolic, main = "", 
     xlab = "age", ylab = "diastolic",
     xlim = c(20,64), ylim = c(0,200))
```

------------------------------------------------------------------------

#### 5- Scatter plot of age and gripForce:

Observation: The grapgic shows a decline in grip force as age increases.
This trend indicates that with age, the strength and efficiency of the
grip force may decrease, This data highlights the importance of
understanding and managing age-related changes in physical performance
and functional abilities.

```{r}
plot(dataset$age, dataset$gripForce, main = "", 
     xlab = "age", ylab = "gripForce",
     xlim = c(20,64), ylim = c(20,71 ))
```

------------------------------------------------------------------------

#### 6- Scatter plot of broad.jump_cm and weight_kg, :

By examining the data in the scatter plot, we can identify potential
trends or patterns. For example, we might notice that athletes with
higher weights tend to have longer broad jump distances. This could
indicate a relationship between weight and broad jump performance,
potentially due to differences in body composition, muscle mass, or
overall strength.

```{r}
dataset
plot(dataset$broad.jump_cm, dataset$weight_kg, 
     xlab = "broad.jump_cm", ylab = "weight_kg",
     xlim = c(0,303), ylim = c(26.3,138 ))
```

------------------------------------------------------------------------

### 4.3 Statistical Measures:

```{r}
 summary(dataset$age)
```

```{r}
summary(dataset$height_cm)
```

```{r}
 summary(dataset$weight_kg)
```

```{r}
 summary(dataset$body.fat_.)
```

```{r}
 summary(dataset$diastolic)
```

```{r}
 summary(dataset$systolic)
```

```{r}
 summary(dataset$gripForce)
```

```{r}
 summary(dataset$sit.and.bend.forward_cm)
```

```{r}
summary(dataset$sit.ups.counts)
```

```{r}
 summary(dataset$broad.jump_cm)
```

------------------------------------------------------------------------

### 4.4 Check duplicated rows:

We check if there are any duplicated rows. that enhancing data quality
which leads to better model performance and speed.

```{r}
sum(duplicated(dataset))
```

we found 1 row that's duplicate that need to be deleted.

```{r}
#Remove duplicated rows 
dataset <- dataset[!duplicated (dataset), ]
```

```{r}
#To make sure that the deletion was successful 
sum(duplicated(dataset))
```

------------------------------------------------------------------------

### 4.5 Check nulls value:

Null values can cause issues when performing data analysis or building
machine learning models, as they can lead to inaccurate results or
errors, where we found then 0 null in our dataset. So, no need to delete
any.

```{r}
#to find the total null values in the dataset
sum(is.na(dataset))
```

------------------------------------------------------------------------

## 4.6 Detect Outlier and Remove them:

We checked our dataset to see if there were any outlier values, and we
found a couple. Statistical studies and modeling can be significantly
impacted by the presence of outliers. Outliers can skew results and
impair the validity and reliability of inferences made from the research
since they are data points that differ dramatically from the majority of
the data. Therefore, in order to prevent them from harming our outcomes,
we must erase them before we begin our task.

```{r}
#install outliers package:
 library(outliers)
```

------------------------------------------------------------------------

#### boxplot to detect outliers:

From The person's age in years boxplot and summary we notice that there
are no outliers showing on the boxplot , Also, we observe that the mean
is less than the median, indicating a down skew (negatively skewed) in
the distribution. This suggests that the age distribution is stretched
towards the lower values, with more individuals falling in the younger
age range.

```{r}
# age boxplot :
boxplot(dataset$age , 
        ylab= "The person’s age in years boxplot", 
        main= "Boxplot of age")
```

------------------------------------------------------------------------

The summary and box plot values for The person's height in cm indicate a
dataset ranging from 125.0 to 193.8. the median at 169.2, and the mean
is 168.6. Comparing the mean and median, we observe that they are
relatively close in value. Also, there is some outliers that we will
handle it by deleting them in preprocessing steps.

```{r}
#Hight boxplot :
boxplot(dataset$height_cm , 
        ylab= "The person’s height in cm", 
        main= "Boxplot of height_cm")

```

------------------------------------------------------------------------

The summary and box plot values for The person's weight in Kg indicate a
dataset ranging from 26.30 to 138.10. The mean weight is 67.45.
Comparing the mean and median, we observe that they are relatively close
in value, and that due also the maximum outliers.

```{r}

#Weight boxplot;
boxplot(dataset$weight_kg , 
        ylab= "The person’s weight in Kg", 
        main= "Boxplot of weight")

```


------------------------------------------------------------------------

The boxplot of the person's body fat (the amount of essential fat .)
shows how the values in the dataset have been evenly distributed around
the median value of 22.80, and, there some outliers that we will handle
them.

```{r}
#body fat boxplot : 
boxplot(dataset$body.fat_.,
        ylab= "the person's body fat" ,
        main= "Boxplot of body fat_%")
```

------------------------------------------------------------------------

The boxplot of the person's diastolic (measures pressure the blood
vessels when the heart is at rest) shows how the values in the dataset
have been evenly distributed around the median value of 79.0, and, there
some outliers that we will handle them

```{r}
#diastolic box plot :
boxplot(dataset$diastolic,
        ylab= "the person's diastolic ",
        main= "Boxplot of diastolic")
```

------------------------------------------------------------------------

The boxplot of the person's systolic (measures pressure in the arteries
when the heart beats in minutes) shows how the values in the dataset
have been evenly distributed around the median value of 130.0, and,
there some outliers that we will handle them.

```{r}
#systolic box plot:
boxplot(dataset$systolic,
        ylab= "The person's systolic " ,
        main= "Boxplot of systolic")
```

------------------------------------------------------------------------

The boxplot of gripForce (fingers flexibility tests) shows how the
values in the dataset have been evenly distributed around the median
value of 37.90, and, there some outliers that we will handle them

```{r}
#gripForce box plot:
boxplot(dataset$gripForc,
        ylab= "the person's gripForce " ,
        main= "Boxplot of gripForc")

```

------------------------------------------------------------------------

the test that's measures flexibility in sitting and bending forward in
centimeters" boxplot illustrates a slight down skew (negatively skewed)
in the distribution, where there are more extreme values on the lower
end(outliers) that we will handle it in preprocessing step by deleting
them.

```{r}
#sit and bend forward_cm box plot: 
boxplot(dataset$sit.and.bend.forward_cm,
        ylab= "sit and bend forward_cm" ,
        main= "Boxplot of sit and bend forward_cm")
```

------------------------------------------------------------------------

The boxplot of the "Test that measures the strength and endurance of the
abdominals and hip-fle" shows how the values in the dataset have been
evenly distributed around the median value of 41, and, there's no
outliers showing on boxplot.

```{r}
#sit-ups counts_cm box plot:
boxplot(dataset$sit.ups.counts,
        ylab= "sit-ups" ,
        main= "Boxplot of sit-ups")
```

------------------------------------------------------------------------

The boxplot of the "method of measuring how far a person can jump from a
standing position to a landing position" shows how the values in the
dataset have been evenly distributed around the median value of 193,
and, there some minimum outliers that we will handle them in
preprocessing step by deleting them.

```{r}
#broad jump_cm box plot:
boxplot(dataset$broad.jump_cm,
        ylab= "broad jump_cm " ,
        main= "Boxplot of broad jump_cm ")
```

------------------------------------------------------------------------

### Detect outlirs:

We noticed that "Age" has an Outlier that it's not showing on the
boxplot, where its an Outlier within the range. that's mean those values
are negatively affects on the dataset even though it is within range.
So, we delete them

```{r}
#Detect outlir for 'age': 
outAge = outlier(dataset$age, logical =TRUE)

#number of outliers:

sum(outAge)
Find_outlier = which(outAge ==TRUE, arr.ind = TRUE)
outAge
Find_outlier

#Delete age outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'height_cm': 
outH = outlier(dataset$height_cm, logical =TRUE)
#number of outliers:
sum(outH)
Find_outlier = which(outH ==TRUE, arr.ind = TRUE)
outH
Find_outlier

#Delete height_cm outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'weight_kg': 
outW= outlier(dataset$weight_kg, logical =TRUE)
#number of outliers:
sum(outW)
Find_outlier = which(outW ==TRUE, arr.ind = TRUE)
outW
Find_outlier

#Delete weight_kg outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'body.fat\_.': 

outefat = outlier(dataset$body.fat_., logical =TRUE)
#number of outliers:
sum(outefat)
Find_outlier = which(outefat ==TRUE, arr.ind = TRUE)
outefat
Find_outlier

#Delete body.fat outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'systolic': 
outesys = outlier(dataset$systolic, logical =TRUE)
#number of outliers:
sum(outesys)
Find_outlier = which(outesys ==TRUE, arr.ind = TRUE)
outesys
Find_outlier

#Delete systolic outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

As we saw in boxplot there was only one outlier. However, here we
detected 3 values, where 2 are within the range but we will take it as
an outliers sinces those values may have a negatively affects on the
dataset specifically on "class" attribute.

```{r}
#Detect outlir for 'gripForce': 
outegrip = outlier(dataset$gripForce, logical =TRUE)
#number of outliers:
sum(outegrip)
Find_outlier = which(outegrip ==TRUE, arr.ind = TRUE)
outegrip
Find_outlier

#Delete gripForce  outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'sit.and.bend.forward_cm': 
outesit = outlier(dataset$sit.and.bend.forward_cm, logical =TRUE)
#number of outliers:
sum(outesit)
Find_outlier = which(outesit ==TRUE, arr.ind = TRUE)
outesit
Find_outlier

#Delete sit.and.bend.forward_cm outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

we notic some outliers within the range and we will deleting them as an
outliers since it's effects other attributes negatively.

```{r}
#Detect outlir for 'sit.up.count': 
outesitup = outlier(dataset$sit.ups.counts, logical =TRUE)
#number of outliers:
sum(outesitup)
Find_outlier = which(outesitup ==TRUE, arr.ind = TRUE)
outesitup
Find_outlier

#Delete age outliers:
dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

```{r}
#Detect outlir for 'broad.jump_cm': 

Outjump = outlier(dataset$broad.jump_cm, logical =TRUE)
sum(Outjump)
Find_outlier = which(Outjump ==TRUE, arr.ind = TRUE)
Outjump
Find_outlier

dataset= dataset[-Find_outlier,]
```

------------------------------------------------------------------------

### Check rows and columns after deletion the outliers:

To make sure that the deletion was successful, we searched for the
number of rows.

```{r}
#Number of rows  
nrow(dataset)
#Number of column
ncol(dataset)
```

We noticed a decrease in the number of rows, which means that deletion
the outliers was successful.

------------------------------------------------------------------------

### 4.7 Discretization :

```{r}
#To use it later in clustering task:
AgeBeforeDis <- dataset$age
```

We transformed the continuous vales of the age into intervals by
dividing the values to be fall on one of three possible interval labels
with equal width which is ( 21, 35],( 35, 49] and ( 49, 63] by
discretisation the values well be meaningful and simpler to classify or
perform other methods that can help us later in our model.^[[3]](https://www.rdocumentation.org/packages/arules/versions/1.6-4/topics/discretize)^

```{r}
# Define bins for discretization
dataset$age=cut(dataset$age, breaks = seq(21,64, by=14), right=FALSE)
```

------------------------------------------------------------------------

### 4.8 Normalizetion:

In order to ensure comparability across individuals and eliminate biases
resulting from differences in measurement units or scales, we have
decided to normalize the following attributes: height (in centimeters),
weight (in kilograms), body fat percentage, diastolic, systolic, grip
force, sit and bend forward distance (in centimeters), sit-ups count,
and broad jump distance (in centimeters).

```{r}
dataset [,3:4:5:6:7:8:9:11]=scale(dataset [,3:4:5:6:7:8:9:11])
```

------------------------------------------------------------------------

### 4.9 Feature Selection :

Based on the dataset and the graphs we did earlier, there are several
justifications for not performing feature selection:

#### 1. Dimensionality:

The number of attributes (12) is not excessively high, and it is within
a manageable range for modeling and analysis.

#### 2. Correlation Assessment:

just because some graphs indicate a lack of correlation between certain
attributes, it doesn't imply that those attributes hold no value or
provide no assistance in enhancing individual body performance. It is
important to recognize the interplay between these attributes and their
impact on body performance. Consequently, removing any of these
attributes may result in loss of valuable information.

#### 3. Interpretability:

By considering all the attributes, you can gain a deeper understanding
of the relationships between different variables, and allows for a more
comprehensive analysis providing more meaningful insights.

While feature selection can be beneficial in certain situations, in the
case of analyzing body performance for individuals, it is important to
consider all attributes without performing feature selection.

------------------------------------------------------------------------

## 5. Data Mining Technique:

### 5.1 Classification:

Our classification objective is to develop a predictive model for our
dataset with class labels A, B, C, and D based on various attributes. To
address the challenge of a small dataset, we will employ a partitioning
strategy suitable for limited data, utilizing three different sizes for
training and testing sets. We will adopt the sampling method, allowing
replacement of attributes with 'True' values. For each partition size,
we will build three decision trees, employing distinct attribute
selection methods: Information Gain (ID3), Gain Ratio (C4.5), and Gini
Index (CART). The prediction will be carried out using the 'predict'
method. Evaluation and testing will be performed using the
'confusionMatrix' method.^[[4]](https://rpubs.com/camguild/803096)^

#### Classification packages:

We install and call predifined packages in R language to help us in
classification process. which shown below:

```{r}
library(party)
library(partykit)
library(RWeka)
library(caret)
library(rpart)
library(rpart.plot)
```

------------------------------------------------------------------------

### Partitioning 70/30

We partition the data the data into (70% training, 30% testing). This
result in 9410 row in the training set and 3983 row in the testing set.

```{r}
set.seed(1234)
ind=sample(2, nrow(dataset), replace=TRUE, prob=c(0.70 , 0.30))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)

# Check class distribution in training set
table(train_data$class)
prop.table(table(train_data$class))

# Check class distribution in testing set
table(test_data$class)
prop.table(table(test_data$class))
```

It appears that both training set and testing set are class balanced,
with the counts for each class being approximately equal. This suggests
that the distribution of instances across different classes in both the
training and testing sets is relatively equal. Each class is represented
proportionally, and there is no significant imbalance where a single
class dominates the dataset. This balance in class representation is
essential for training machine learning models, contributing to fair and
unbiased predictions across all classes.

------------------------------------------------------------------------

#### Information Gain (ID3):

```{r}
features <-dataset[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")]
target <- as.factor(dataset$class)
dataset$class = as.factor(dataset$class)


# Example of hyperparameter tuning
model <- train(
  x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,
  method = "rpart",parms = list(split = "information"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3)
)
```

The shown matrix based on training data.

#### Tree based on information gain:

```{r}
# Load the necessary libraries
library(rpart)
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model,main="ID3 70/30", box.palette = "auto", nn = TRUE)
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest
information gain. As a result, it was placed at the root level,
representing the first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

The above matrix is based on applying our model on test data.

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.6%  |
| Error Rate          | 42.4%  |
| Sensitivity(Recall) | 43.88% |
| Specificity         | 60,5%  |
| Precision           | 60.5%% |

: Table 2: Information Gain evaluation

------------------------------------------------------------------------

#### Gain ratio:

```{r}
# Example of hyperparameter tuning
model <- train(
  x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,
  method = "rpart",parms = list(split = "gain_ratio"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3)
)
```

The shown matrix based on training data.

#### Tree based on Gain ratio:

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model,main="c4.5 70/30", box.palette = "auto", nn = TRUE)
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest gain
ratio. As a result, it was placed at the root level, representing the
first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

The above matrix is based on applying our model on test data.

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.86% |
| Error Rate          | 42.14% |
| Sensitivity(Recall) | 41.42% |
| Specificity         | 60.59% |
| Precision           | 60.59% |

: Table 3: Gain Ratio evaluation

------------------------------------------------------------------------

#### Gini index:

```{r}
# Example of hyperparameter tuning
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "gini"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

#### Tree based on Gini index :

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model, main = "Decision Tree for CART 70/30")
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest Gini index
(impurity reduction) values. As a result, it was placed at the root
level, representing the first level of the tree.

### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

The above matrix is based on applying our model on test data.

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.86% |
| Error Rate          | 42.14% |
| Sensitivity(Recall) | 41.42% |
| Specificity         | 60.59% |
| Precision           | 60.59% |

: Table 4: Gini index evaluation

------------------------------------------------------------------------

### Partitioning 75/25

We partition the data the data into (75% training, 25% testing). This
result in 10070 row in the training set and 3323 row in the testing set.

```{r}
set.seed(1234)
ind=sample (2, nrow(dataset), replace=TRUE, prob=c(0.75 , 0.25))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)

# Check class distribution in training set
table(train_data$class)
prop.table(table(train_data$class))

# Check class distribution in testing set
table(test_data$class)
prop.table(table(test_data$class))
```

the class is balanced in the training set and testing set.

------------------------------------------------------------------------

#### Information Gain (ID3):

```{r}
features <-dataset[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")]
target <- as.factor(dataset$class)
dataset$class = as.factor(dataset$class)

# Example of hyperparameter tuning
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "information"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

The shown matrix based on training data.

#### Tree based on information gain:

```{r}
# Load the necessary libraries
library(rpart)
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model,main="ID3 75/25", box.palette = "auto", nn = TRUE)
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest
information gain. As a result, it was placed at the root level,
representing the first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

The above matrix is based on applying our model on test data.

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.8%  |
| Error Rate          | 42.20% |
| Sensitivity(Recall) | 43.86% |
| Specificity         | 60.97% |
| Precision           | 60.97% |

: Table 6:

------------------------------------------------------------------------

#### Gain ratio:

```{r}
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "gain_ratio"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

The shown matrix based on training data.

#### Tree based on Gain ratio:

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model,main="c4.5 75/25", box.palette = "auto", nn = TRUE)
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest gain
ratio. As a result, it was placed at the root level, representing the
first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.58% |
| Error Rate          | 42.41% |
| Sensitivity(Recall) | 40.20% |
| Specificity         | 52.47% |
| Precision           | 61.81% |

: Table 7:

------------------------------------------------------------------------

#### Gini index:

```{r}
# Example of hyperparameter tuning
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "gini"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

#### Tree based on Gini index :

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model, main = "Decision Tree for CART 75/25")
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest Giniindex
(impurity reduction) values. As a result, it was placed at the root
level, representing the first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

#### Schedule for classification Evaluation:

| Evaluation method   | value |
|---------------------|-------|
| Accuracy            | 57.58 |
| Error Rate          | 42.41 |
| Sensitivity(Recall) | 40.20 |
| Specificity         | 61.81 |
| Precision           | 61.81 |

: Table 8:

------------------------------------------------------------------------

#### Partitioning 80/20

We partition the data the data into (80% training, 20% testing). This
result in 10708 row in the training set and 2685 row in the testing set.

```{r}
set.seed(1234)
ind=sample (2, nrow(dataset), replace=TRUE, prob=c(0.80 , 0.20))
train_data=dataset[ind==1,]
test_data=dataset[ind==2,]
dim(train_data)
dim(test_data)

# Check class distribution in training set
table(train_data$class)
prop.table(table(train_data$class))

# Check class distribution in testing set
table(test_data$class)
prop.table(table(test_data$class))
```

------------------------------------------------------------------------

#### Information Gain (ID3):

```{r}
features <-dataset[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")]
target <- as.factor(dataset$class)
dataset$class = as.factor(dataset$class)

model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "information"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

The shown matrix based on training data.

#### Tree based on information gain:

```{r}
# Load the necessary libraries
library(rpart)
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model, box.palette = "auto", nn = TRUE, main = "Decision Tree for CART 80/20")
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest
information gain. As a result, it was placed at the root level,
representing the first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

The above matrix is based on applying our model on test data. \####
Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.48% |
| Error Rate          | 42,51% |
| Sensitivity(Recall) | 43.56% |
| Specificity         | 61.18% |
| Precision           | 61.18% |

: Table 9:

------------------------------------------------------------------------

#### Gain ratio:

```{r}
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "gain_ratio"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

The shown matrix based on training data.

#### Tree based on Gain ratio:

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model,main="c4.5 80/20", box.palette = "auto", nn = TRUE)
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest gain
ratio. As a result, it was placed at the root level, representing the
first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.37% |
| Error Rate          | 42.63% |
| Sensitivity(Recall) | 43.32% |
| Specificity         | 61.95% |
| Precision           | 61.95% |

: Table 10:

------------------------------------------------------------------------

#### Gini index:

```{r}
# Example of hyperparameter tuning
model <- train(x = train_data[, c("gender","age" ,"height_cm",  "weight_kg" , "body.fat_.", "diastolic", "systolic","gripForce", "sit.and.bend.forward_cm","sit.ups.counts","broad.jump_cm")],
  y = train_data$class,method = "rpart",parms = list(split = "gini"),tuneGrid = data.frame(cp = seq(0.01, 0.1, by = 0.01)),trControl = trainControl(method = "cv", number = 3))
```

#### Tree based on Gini index :

```{r}
# Load the necessary libraries
library(rpart.plot)

# Assuming 'model' is your trained model
rpart_model <- model$finalModel

# Print the decision tree
rpart.plot(rpart_model, main = "Decision Tree for CART 80/20")
```

The decision tree representation was utilized, and the findings indicate
that the attribute (sit.and.bend.forward_cm) has the greatest Giniindex
(impurity reduction) values. As a result, it was placed at the root
level, representing the first level of the tree.

#### Prediction on test data and Confusion matrix:

```{r}
testPred<- predict(model,newdata=test_data)
testPred<- factor(testPred)
test_data$class <- factor(test_data$class)
results<- confusionMatrix(testPred,test_data$class)
conf_matrix <- results$table

print(results)

error_rate <- 1 - sum(diag(conf_matrix)) / sum(conf_matrix)
precision <- diag(conf_matrix) / rowSums(conf_matrix)
specificity <- conf_matrix[1, 1] / sum(conf_matrix[1, ])
sensitivity <- conf_matrix[2, 2] / sum(conf_matrix[2, ])

print(paste("specificity:", specificity))
print(paste("sensitivity", sensitivity))
print(paste("Error Rate:", error_rate))
print(paste("Precision for Class 1:", precision[1]))
```

#### Schedule for classification Evaluation:

| Evaluation method   | value  |
|---------------------|--------|
| Accuracy            | 57.37% |
| Error Rate          | 42.63% |
| Sensitivity(Recall) | 43.32% |
| Specificity         | 61.95% |
| Precision           | 61.95% |

: Table 11:

------------------------------------------------------------------------

#### Classification Analysis:

ID3:

Accuracy for 70/30 partitioning: 0.576 Accuracy for 75/25 partitioning:
0.578 Accuracy for 80/20 partitioning: 0.5748 C4.5:

Accuracy for 70/30 partitioning: 0.5786 Accuracy for 75/25 partitioning:
0.5758 Accuracy for 80/20 partitioning: 0.573 CART:

Accuracy for 70/30 partitioning: 0.5786 Accuracy for 75/25 partitioning:
0.5758 Accuracy for 80/20 partitioning: 0.5737 Analysis:

Overall, the accuracy values for the three decision tree algorithms
(ID3, C4.5, and CART) are relatively close across different partition
sizes.

The highest accuracy is observed for C4.5 at 70/30 partitioning
(0.5786), followed closely by CART and ID3 at the same partition size.

ID3 performs consistently across different partition sizes, maintaining
accuracy around 0.576 to 0.578.

C4.5 and CART show slight variations in accuracy across partition sizes
but generally stay close to each other.

The impact of changing partition sizes on accuracy seems minimal, with
fluctuations within a narrow range.

------------------------------------------------------------------------

### 5.2 Clustering:

Data clustering is the act of dividing data into distinct groups or
clusters. It is an unsupervised learning technique, meaning it doesn't
rely on known class labels "Class" in the training data. The data within
each cluster share similarities with one another and differ from data in
other clusters. In this case, we will employ the k-means clustering
algorithm.^[[5]](https://rpubs.com/odenipinedo/cluster-analysis-in-R)^

### 1- Data preprocessing before Clustering:

In order to optimize the performance of our models and achieve the most
accurate results, it is crucial to preprocess certain attributes before
applying data clustering techniques. where we will:

1-Remove the class label.

2-Adding the old Age attribute "before discretizing".

3-convert all attribute into numeric data type.

#### 1.1: Remove Class lable:

For unsupervised learning, At first we need to removing class label
"Class".

```{r}
#in case we need the dataset with class label
dataWithclass <-dataset 

#delete class label
dataset <- dataset [,-which(names(dataset)== "class")]                    

#varify removing class
str(dataset)
```

As Showing in data frame above, deletion the "calss" attribute was
successful.

------------------------------------------------------------------------

#### 1.2 Add Age Before discretization:

Based on our previous findings about discretizing the age attribute, we
discovered that using fixed intervals may not accurately represent the
true distribution of the data. This can result in biased or inaccurate
cluster assignments.

To overcome this issue, we suggest removing the discretized age
attribute and adding the original age attribute called "AgeBeforeDis".
This change is expected to improve the performance of our model, make
the analysis easier, and enable more straightforward comparisons between
different group.

```{r}
dataset$age <- AgeBeforeDis

#verify updating
str(dataset)
```

As Showing that age attribute becomes on continuous value, which means
updating age was successful.

------------------------------------------------------------------------

#### 1.3 Check datatype:

for Clustering task all data types should be numeric, and from the data
frame from last chunk ,there is only one attribute that should be
convert, which is gender attribute. where Encoding gender attribute
makes data type to Factor, so we should convert it to numeric before
clustering.

#### Convert gender attribute type to numeric:

```{r}
dataset$gender <- as.numeric(as.character(dataset$gender))

# Verify the conversion and all other attribute class type
sapply(dataset, class)
```

Now all attribute are numeric, so we are ready to perform k-means
clustering.

------------------------------------------------------------------------

#### determine and visualize optimal number of clusters:

In order to determine the optimal number of clusters (k) for our
dataset, we will experiment with three different sizes of k for
clustering. To assist with this determination, we will employ various
methods( kmeansruns, calculate the average silhouette ,total
within-cluster sum of square (Elbow method) and the BCubed (precision
and recall) ) that aid in identifying the most suitable k value for our
specific dataset. also, we employed three different methods. It should
be noted that the identification of the correct k value from the 3
resulte from each method is may vary. However, utilizing these three
methods aids in studying the three most suitable k values for the
dataset.

```{r}
#install necessary packages:
library(factoextra)
library(fpc)
library(cluster)
library(NbClust)
```

#### a) kmeansruns method:

This function assigns data points to clusters based on proximity to
centroids. To determine the optimal number of clusters,different
techniques like the elbow method or silhouette analysis can be used.
This helps identify the value of k that produces the best clustering
performance.

```{r}
library(fpc)
kmeansruns.result <- kmeansruns(dataset)  
kmeansruns.result 
```

#### Visualize clustering:

```{r}
fviz_cluster(kmeansruns.result, data = dataset)
```

According to the method's output, method suggests using k=3 cluster for our dataset, and we'll try another approach to see what performs best between them. 

from the above results and the cluster representation. First cluster contains 2927 objects with total sum of square 79739.78 . Second cluster contains 3364 object with total sum of square 99564.13 . third cluster contains 6760 objects with total sum of sequare 131047.67. The value of the total sum of square indicate that the larger value means the larger seperation. So,the object in the third cluster are more separated than the object in the first and second cluster.

------------------------------------------------------------------------

#### b) Average silhouette method:

This method calculates the average silhouette width for different values
of k, determining how well data points fit into their assigned clusters.

```{r}
library(NbClust)
library(factoextra) 

fviz_nbclust(dataset, kmeans, method = "silhouette")+ labs(subtitle = "Silhouette method")
```

From the plot above we noticed that k = 2 has the highest average
sillhouette width approximately (0.6). This indicates a relatively
well-defined and distinct separation between the clusters, suggesting a
higher level of coherence within each cluster compared to other values
of k.

------------------------------------------------------------------------

#### c) total within-cluster sum of square method:

This method determines the number of clusters according to the turning
point in a curve, the curve is plotted using the total within-cluster
sum of square (WSS) as in y-axis, and Noumber of clusters in x-axis

```{r}
library(factoextra) 

fviz_nbclust(dataset, kmeans, method = "wss") +
  geom_vline(xintercept = 4, linetype = 3)+
  labs(subtitle = "Elbow method")
```

The output of the this method recommends that we use k=3 cluster for our
dataset.

------------------------------------------------------------------------

#### Visualization of Cluters:

In this section, we will perform k-means clustering and visualize its
result using three different k's that have been chosen based on methods
that we tasted earlier k=2(highest average sillhouette width), k=3(from
Kmeansruns and Elbow method), k=4(3nd highest average sillhouette width
after k=2,3). then we will compute WSS and Bcubed preceision and recall
and average silhouette for each cluster as methods of evaluating
clustering results.

### First Cluster: 2-Means Cluster:

Calculate K-means for k=2:

```{r}
#set a seed for random number generation to make the results reproducible
set.seed(8953)

kmeans.result <- kmeans(dataset, 2)

# print the clusterng result
kmeans.result
```

#### Visualize 2 clusters:

```{r}
library(factoextra)
fviz_cluster(kmeans.result, data = dataset)
```

Based on the above results and cluster representation, the first cluster contains 4620 objects with a total sum of squares of 285656.3, while the second cluster contains 8431 objects with a total sum of squares of 305408.3. The higher total sum of squares in the second cluster suggests a larger separation, indicating that the objects in the second cluster are more dispersed or separated compared to those in the first cluster. A lower WSS value indicates that the objects within the cluster are closer to the centroid, suggesting a more compact and well-defined cluster.Overall,
The clustering algorithm has achieved a 75.3% separation, suggesting that the clusters are relatively well-defined and distinct from each other.

#### Average silhouette for 2 clusters

```{r}
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(dataset)) 

fviz_silhouette(avg_sil)
```

#### Within cluster sum of squares by cluster:

```{r}
kmeans.result$tot.withinss
```

#### BCubed precision and recall for k=2:

```{r}
cluster_assignments <- c(kmeans.result$cluster)
ground_truth_labels <- c(dataWithclass$class)

data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
```

-The silhouette width and WCSS suggest that k=2 provides a reasonable
clustering solution, with well-defined and compact clusters.

-The BCubed Precision and Recall values indicate the effectiveness of
the clustering with respect to the ground truth labels. A Precision of
0.25 suggests that about 25% of instances within the same cluster have
the same ground truth label, while a Recall of 0.55 indicates that about
55% of instances with the same ground truth label are in the same
cluster.

------------------------------------------------------------------------

### Second cluster: 3-Means Cluster:

```{r}
#set a seed for random number generation  to make the results reproducible
set.seed(8953)
kmeans.result <- kmeans(dataset, 3)

# print the clusterng result
kmeans.result
```

#### Visualize 3 clusters

```{r}
# visualize clustering (2 clusters)
#install.packages("factoextra")
library(factoextra)
fviz_cluster(kmeans.result, data = dataset)
```

we can infer that the clustering algorithm has successfully separated the data into three distinct clusters. Cluster 1 has the lowest total sum of square value, followed by Cluster 3, and Cluster 2 has the highest total sum of square value.Therefore, Cluster 1 appears to be the most compact and well-defined cluster, while Cluster 2 shows a higher level of dispersion. Overall, the clustering algorithm has achieved an 87.0% separation, indicating a relatively high level of separation and distinctiveness between the three clusters.

#### Average silhouette for 3 clusters

```{r}
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(dataset)) 

fviz_silhouette(avg_sil)
```

#### Within cluster sum of squares by cluster:

```{r}
kmeans.result$tot.withinss
```

#### BCubed precision and recall for k=3:

```{r}
cluster_assignments <- c(kmeans.result$cluster)
ground_truth_labels <- c(dataWithclass$class)

data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
```

-The average silhouette width of 0.54 suggests that there is a moderate
separation between clusters, but it might not be as distinct as in the
case of k=2.

-The lower WCSS (310351.6) compared to k=2 implies that the clusters are
more compact, indicating that data points within each cluster are closer
to each other. -These values indicate that about 25% of instances within
the same cluster have the same ground truth label (Precision), and about
39% of instances with the same ground truth label are in the same
cluster (Recall).

------------------------------------------------------------------------

### Third cluster: 4-Means Cluster :

```{r}
#set a seed for random number generation  to make the results reproducible
set.seed(8953)
kmeans.result <- kmeans(dataset, 4)

# print the clusterng result
kmeans.result
```

#### Visualize 4 clusters:

```{r}
# visualize clustering (2 clusters)
#install.packages("factoextra")
library(factoextra)
fviz_cluster(kmeans.result, data = dataset)
```

Based on the above results and cluster representation, First cluster contains 2584 objects with total sum of square 56577.82. Second cluster contains 3111 object with total sum of square 53341.05 . Third cluster contains 2508 objects with total sum of sequare 58639.75. Fourth cluster contains  4848 objects with total sum of sequare 61490.52, which is the highest total sum of squares. A higher sum of squares indicates a larger separation. Therefore, the objects in the fourth cluster are more separated. Cluster 2 has the lowest WSS value, followed by Cluster 1, Cluster 3, and Cluster 4. Therefore, Cluster 2 appears to be the most compact and well-defined cluster, while Cluster 4 shows a higher level of dispersion. Overall, the clustering algorithm has achieved a 90.4% separation, indicating a relatively high level of separation and distinctiveness between the four clusters.

#### Average silhouette for 4 clusters:

```{r}
library(cluster)
avg_sil <- silhouette(kmeans.result$cluster,dist(dataset)) 

fviz_silhouette(avg_sil)
```

#### Within cluster sum of squares by cluster:

```{r}
kmeans.result$tot.withinss
```

#### BCubed precision and recall for k=4:

```{r}
cluster_assignments <- c(kmeans.result$cluster)
ground_truth_labels <- c(dataWithclass$class)

data <- data.frame(cluster = cluster_assignments, label = ground_truth_labels)

# Function to calculate BCubed precision and recall
calculate_bcubed_metrics <- function(data) {
  n <- nrow(data)
  precision_sum <- 0
  recall_sum <- 0

  for (i in 1:n) {
    cluster <- data$cluster[i]
    label <- data$label[i]
    
# Count the number of items from the same category within the same cluster
same_category_same_cluster <- sum(data$label[data$cluster == cluster] == label)
    
# Count the total number of items in the same cluster
total_same_cluster <- sum(data$cluster == cluster)
    
# Count the total number of items with the same category
total_same_category <- sum(data$label == label)
    
# Calculate precision and recall for the current item and add them to the sums
precision_sum <- precision_sum + same_category_same_cluster /total_same_cluster
recall_sum <- recall_sum + same_category_same_cluster / total_same_category
  }

  # Calculate average precision and recall
  precision <- precision_sum / n
  recall <- recall_sum / n

  return(list(precision = precision, recall = recall))
}

# Calculate BCubed precision and recall
metrics <- calculate_bcubed_metrics(data)

# Extract precision and recall from the metrics
precision <- metrics$precision
recall <- metrics$recall

# Print the results
cat("BCubed Precision:", precision, "\n")
cat("BCubed Recall:", recall, "\n")
```

-The average silhouette width of 0.42 suggests a moderate level of
separation between clusters, indicating that the clusters are
distinguishable, but there may be some overlap. -The lower WCSS
indicates that the clusters are relatively compact, with instances
within each cluster being closer to each other.

-The BCubed metrics : A Precision of 0.25 means that about 25% of
instances within the same cluster have the same ground truth label. A
Recall of 0.27 means that about 27% of instances with the same ground
truth label are in the same cluster.

------------------------------------------------------------------------

## 6. Evaluation and Comparison:

### 6.1 Classification:

80% training 20% testing:

|                     |        |          |            |
|---------------------|--------|----------|------------|
|                     | GI     | GI ratio | Gini Index |
| Accuracy            | 57.48% | 57.37%   | 57.37%     |
| Sensitivity(Recall) | 43.56% | 43.32%   | 43.32%     |
| Specificity         | 61.18% | 61.95%   | 61.95%     |
| Precision           | 61.18% | 61.95%   | 61.95%     |

: Table 12:



In this partitioning, GI exhibits a slightly higher accuracy, suggesting that it may be marginally more predictive than the other algorithms, albeit with a small difference.

75% training 25% testing:

|                     |        |          |            |
|---------------------|--------|----------|------------|
|                     | GI     | GI ratio | Gini Index |
| Accuracy            | 57.8%  | 57.58%   | 57.58%     |
| Sensitivity(Recall) | 43.86% | 40.20%   | 40.20%     |
| Specificity         | 60.97% | 52.47%   | 52.47%     |
| Precision           | 60.97% | 61.81%   | 61.81%     |

: Table 13:

 in 75/25 GI stands out with slightly higher accuracy, sensitivity, and specificity compared to GI ratio and Gini Index. These metrics collectively suggest that GI performs slightly better in correctly classifying instances, especially in identifying positive and negative cases.



70% training 30% testing:

|                     |        |          |            |
|---------------------|--------|----------|------------|
|                     | GI     | GI ratio | Gini Index |
| Accuracy            | 57.6%  | 57.86%   | 57.86%     |
| Sensitivity(Recall) | 43.88% | 41.42%   | 41.42%     |
| Specificity         | 60.5%  | 60.59%   | 60.59%     |
| Precision           | 60.5%  | 60.59%   | 60.59%     |

: Table 14:


with a 70%-30% training-testing split, GI ratio slightly outperforms the other algorithms in terms of accuracy and specificity. However, GI maintains a higher sensitivity, suggesting better performance in identifying positive instances. The precision values are consistent across all algorithms. Overall, the choice of algorithm may depend on specific priorities, such as whether false positives or false negatives carry more significance in the given context.

------------------------------

### 6.2 Clustering:

+--------------+--------------+--------------+--------------+
| No. of       | k=2 (best)   | k=3          | k=4          |
| Clusters     |              |              |              |
+:============:+:============:+:============:+:============:+
| Average      | cluter       | clute        | clute        |
| Silhouette   | 1=0.56,      | r1=0.58 ,    | r1=0.55 ,    |
| width for    |              | clute        | clute        |
| each cluter  | clute        | r2=0.60 ,    | r2=0.30 ,    |
|              | r2=0.67      | clute        | clute        |
|              |              | r3=0.41      | r3=0.37      |
|              |              |              | ,clute       |
|              |              |              | r4=0.46      |
+--------------+--------------+--------------+--------------+
| Average      | 0.63         | 0.54         | 0.42         |
| Silhouette   |              |              |              |
| width        |              |              |              |
+--------------+--------------+--------------+--------------+
| Total        | 5 91064.6    | 3 10351.6    | 2 30049.1    |
| within-      |              |              |              |
| cluster sum  |              |              |              |
| of square    |              |              |              |
+--------------+--------------+--------------+--------------+
| BCubed       | 0 . 2516112  | 0 . 2516393  | 0 . 2522583  |
| Precison     |              |              |              |
+--------------+--------------+--------------+--------------+
| BCubed       | 0 . 5454527  | 0 .387276    | 0 . 2729353  |
| Recall       |              |              |              |
+--------------+--------------+--------------+--------------+

: Table 15: Comparison clusters

Upon comparing the results of the clustering task using the k-means
algorithm reveal that the most effective cluster configuration is
achieved when k=2. This is supported by the higher average silhouette
width for cluster 2 (0.67) compared to the other clusters in different
configurations. It suggests that instances within cluster 2 are closely
grouped and well-separated from instances in other clusters, indicating
a higher level of cohesion and separation. Furthermore, the overall
average silhouette width for k=2 (0.63) surpasses the average values for
k=3 (0.54) and k=4 (0.42), indicating better overall clustering
performance.

However, it's important to note that there is still some overlap between
the clusters in all configurations. This is evident from the BCubed
precision and recall measures, which suggest that the clusters do not
perfectly capture the true underlying structure of the data. For
example, with k=2, the BCubed precision is 0.2516112, indicating that
only around 25% of the instances within each cluster are correctly
clustered together. Similarly, the BCubed recall is 0.5454527,
suggesting that only approximately 27% of the instances that should
belong to a specific cluster are actually assigned to that cluster.


------------------------------------------------------------------------

## 7. Finding:

Based on Comparison Criteria, it appears that the clustering algorithm has achieved a relatively high average silhouette width of 63%, indicating that the clusters generated are well-separated and the instances within each cluster are similar to one another. This suggests that the clustering algorithm has successfully identified distinct groups or patterns in our body performance dataset. While the Classification accuracy achieved is 57.86%. This means that the classification model correctly predicted the class labels for 57.86% of the instances in the test set. Therefor, Clustering can be more suitable.

However, Considering the project's goal and the problem at hand, the clustering task encountered challenges primarily due to the presence of overlapping clusters. While the clustering task facilitated the understanding of similarities among body performance data points, it did not directly contribute to problem-solving or goal attainment. while the classification task emerged as the more advantageous approach for analysis. By assigning class labels to the data, the classification task enabled the identification of influential factors significantly impacting body scores. (The decision tree algorithm provided valuable insights into these factors), shedding light on their importance and relationships. However, the accurcy does not provide quality of the classification model.

In summary, considering the similar percentage result achieved by both classification and clustering approaches, we made the decision to choose classification due to its direct suitability to our specific problem and its effective ability to accurately classify the data.^[[6]](https://www.kaggle.com/code/shivanirana63/guide-to-complete-statistical-analysis)^

------------------------------------------------------------------------

## 8. References:

[1] [“Body performance Data,” Kaggle, Jun. 29, 2022. ](https://www.kaggle.com/datasets/kukuroo3/body-performance-data)

[2].[Codeguyas, “Body Performance Data EDA,” Kaggle, Dec. 19, 2021.](https://www.kaggle.com/code/codeguyas101/body-performance-data-eda)

[3].
[“discretize function - RDocumentation.”](https://www.rdocumentation.org/packages/arules/versions/1.6-4/topics/discretize)

[4].[“RPubs - Classification and Regression Trees (CART) in R.”](https://rpubs.com/camguild/803096)

[5]. [“RPubs - Cluster Analysis in R.”](https://rpubs.com/odenipinedo/cluster-analysis-in-R)

[6].[Shivanirana, “📌🧐Guide to Complete Statistical Analysis📊✅,” Kaggle, Mar. 11, 2022. ](https://www.kaggle.com/code/shivanirana63/guide-to-complete-statistical-analysis)

[overall].[Body performance note
book](https://rpubs.com/TeraPutera/LBB-CM-2)
